{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_zh</th>\n",
       "      <th>title2_zh</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017养老保险又新增两项，农村老人人人可申领，你领到了吗</td>\n",
       "      <td>警方辟谣“鸟巢大会每人领5万” 仍有老人坚持进京</td>\n",
       "      <td>There are two new old-age insurance benefits f...</td>\n",
       "      <td>Police disprove bird's nest congress each pers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小</td>\n",
       "      <td>If you do not come to Shenzhen, sooner or late...</td>\n",
       "      <td>Shenzhen's GDP outstrips Hong Kong Shenzhen St...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>GDP首超香港？深圳澄清：还差一点点……</td>\n",
       "      <td>If you do not come to Shenzhen, sooner or late...</td>\n",
       "      <td>The GDP overtopped Hong Kong Shenzhen clarifie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>去年深圳GDP首超香港？深圳统计局辟谣：还差611亿</td>\n",
       "      <td>If you do not come to Shenzhen, sooner or late...</td>\n",
       "      <td>Shenzhen's GDP topped Hong Kong last year Shen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>\"用大蒜鉴别地沟油的方法,怎么鉴别地沟油</td>\n",
       "      <td>吃了30年食用油才知道，一片大蒜轻松鉴别地沟油</td>\n",
       "      <td>How to discriminate oil from gutter oil by mea...</td>\n",
       "      <td>It took 30 years of cooking oil to know that o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  tid1  tid2                          title1_zh  \\\n",
       "0   0     0     1      2017养老保险又新增两项，农村老人人人可申领，你领到了吗   \n",
       "1   3     2     3  \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港   \n",
       "2   1     2     4  \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港   \n",
       "3   2     2     5  \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港   \n",
       "4   9     6     7               \"用大蒜鉴别地沟油的方法,怎么鉴别地沟油   \n",
       "\n",
       "                    title2_zh  \\\n",
       "0    警方辟谣“鸟巢大会每人领5万” 仍有老人坚持进京   \n",
       "1   深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小   \n",
       "2        GDP首超香港？深圳澄清：还差一点点……   \n",
       "3  去年深圳GDP首超香港？深圳统计局辟谣：还差611亿   \n",
       "4     吃了30年食用油才知道，一片大蒜轻松鉴别地沟油   \n",
       "\n",
       "                                           title1_en  \\\n",
       "0  There are two new old-age insurance benefits f...   \n",
       "1  If you do not come to Shenzhen, sooner or late...   \n",
       "2  If you do not come to Shenzhen, sooner or late...   \n",
       "3  If you do not come to Shenzhen, sooner or late...   \n",
       "4  How to discriminate oil from gutter oil by mea...   \n",
       "\n",
       "                                           title2_en  label  \n",
       "0  Police disprove bird's nest congress each pers...      0  \n",
       "1  Shenzhen's GDP outstrips Hong Kong Shenzhen St...      0  \n",
       "2  The GDP overtopped Hong Kong Shenzhen clarifie...      0  \n",
       "3  Shenzhen's GDP topped Hong Kong last year Shen...      0  \n",
       "4  It took 30 years of cooking oil to know that o...      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_zh</th>\n",
       "      <th>title2_zh</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>321187</td>\n",
       "      <td>167562</td>\n",
       "      <td>59521</td>\n",
       "      <td>萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大</td>\n",
       "      <td>辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？</td>\n",
       "      <td>There are two new old-age insurance benefits f...</td>\n",
       "      <td>Police disprove bird's nest congress each pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321190</td>\n",
       "      <td>167564</td>\n",
       "      <td>91315</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国</td>\n",
       "      <td>If you do not come to Shenzhen, sooner or late...</td>\n",
       "      <td>Shenzhen's GDP outstrips Hong Kong Shenzhen St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321189</td>\n",
       "      <td>167563</td>\n",
       "      <td>167564</td>\n",
       "      <td>萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>If you do not come to Shenzhen, sooner or late...</td>\n",
       "      <td>The GDP overtopped Hong Kong Shenzhen clarifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321193</td>\n",
       "      <td>167564</td>\n",
       "      <td>160994</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>被绞刑处死的萨达姆是替身？他的此男人举动击破替身谣言！</td>\n",
       "      <td>If you do not come to Shenzhen, sooner or late...</td>\n",
       "      <td>Shenzhen's GDP topped Hong Kong last year Shen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321191</td>\n",
       "      <td>167564</td>\n",
       "      <td>15084</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>中国川贝枇杷膏在美国受到热捧？纯属谣言！</td>\n",
       "      <td>How to discriminate oil from gutter oil by mea...</td>\n",
       "      <td>It took 30 years of cooking oil to know that o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    tid1    tid2                        title1_zh  \\\n",
       "0  321187  167562   59521  萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大   \n",
       "1  321190  167564   91315              萨达姆被捕后告诫美国的一句话，发人深思   \n",
       "2  321189  167563  167564    萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗   \n",
       "3  321193  167564  160994              萨达姆被捕后告诫美国的一句话，发人深思   \n",
       "4  321191  167564   15084              萨达姆被捕后告诫美国的一句话，发人深思   \n",
       "\n",
       "                     title2_zh  \\\n",
       "0  辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？   \n",
       "1    10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国   \n",
       "2          萨达姆被捕后告诫美国的一句话，发人深思   \n",
       "3  被绞刑处死的萨达姆是替身？他的此男人举动击破替身谣言！   \n",
       "4         中国川贝枇杷膏在美国受到热捧？纯属谣言！   \n",
       "\n",
       "                                           title1_en  \\\n",
       "0  There are two new old-age insurance benefits f...   \n",
       "1  If you do not come to Shenzhen, sooner or late...   \n",
       "2  If you do not come to Shenzhen, sooner or late...   \n",
       "3  If you do not come to Shenzhen, sooner or late...   \n",
       "4  How to discriminate oil from gutter oil by mea...   \n",
       "\n",
       "                                           title2_en  \n",
       "0  Police disprove bird's nest congress each pers...  \n",
       "1  Shenzhen's GDP outstrips Hong Kong Shenzhen St...  \n",
       "2  The GDP overtopped Hong Kong Shenzhen clarifie...  \n",
       "3  Shenzhen's GDP topped Hong Kong last year Shen...  \n",
       "4  It took 30 years of cooking oil to know that o...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>347448</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>347449</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>359100</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>359101</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>359102</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id   Category\n",
       "0  347448  unrelated\n",
       "1  347449  unrelated\n",
       "2  359100  unrelated\n",
       "3  359101  unrelated\n",
       "4  359102  unrelated"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")\n",
    "sub = pd.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "train_df[\"title1_en\"] = train_df[\"title1_en\"].apply(lambda x: x.replace('\"\"', '').replace('\"', '').replace(\"!\", \"\").replace(\"?\", \"\"))\n",
    "train_df[\"title2_en\"] = train_df[\"title2_en\"].apply(lambda x: x.replace('\"\"', '').replace('\"', '').replace(\"!\", \"\").replace(\"?\", \"\"))\n",
    "\n",
    "test_df[\"title1_en\"] = train_df[\"title1_en\"].apply(lambda x: x.replace('\"\"', '').replace('\"', '').replace(\"!\", \"\").replace(\"?\", \"\"))\n",
    "test_df[\"title2_en\"] = train_df[\"title2_en\"].apply(lambda x: x.replace('\"\"', '').replace('\"', '').replace(\"!\", \"\").replace(\"?\", \"\"))\n",
    "\n",
    "train_df.replace('unrelated', 0, inplace=True)\n",
    "train_df.replace('agreed', 1, inplace=True)\n",
    "train_df.replace('disagreed', 2, inplace=True)\n",
    "\n",
    "y = list(train_df[\"label\"])\n",
    "\n",
    "display(train_df.head()) \n",
    "display(test_df.head())\n",
    "display(sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(train_df[\"title2_en\"])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682fce60a5604f42b7807cbb5acc4264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=320552), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43deec481568439ab1a55e1bc8851e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80126), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99853"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t1 = train_df[\"title1_en\"]\n",
    "train_t2 = train_df[\"title2_en\"]\n",
    "\n",
    "test_t1 = test_df[\"title1_en\"]\n",
    "test_t2 = test_df[\"title2_en\"]\n",
    "\n",
    "label = train_df[\"label\"]\n",
    "\n",
    "\n",
    "word_to_ix = {}\n",
    "for title1, title2 in zip(tqdm(train_t1), train_t2):\n",
    "    for word in title1.split():\n",
    "        if word not in word_to_ix.keys():\n",
    "            word_to_ix[word] = len(word_to_ix)+1\n",
    "    for word in title2.split():\n",
    "        if word not in word_to_ix.keys():\n",
    "            word_to_ix[word] = len(word_to_ix)+1\n",
    "            \n",
    "            \n",
    "for title1, title2 in zip(tqdm(test_t1), test_t2):\n",
    "    for word in title1.split():\n",
    "        if word not in word_to_ix.keys():\n",
    "            word_to_ix[word] = len(word_to_ix)+1\n",
    "    for word in title2.split():\n",
    "        if word not in word_to_ix.keys():\n",
    "            word_to_ix[word] = len(word_to_ix)+1\n",
    "\n",
    "len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class TitleDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    " \n",
    "    def __init__(self, titles1, titles2, labels, dic=None, transform=None, seq_length=50, if_test=False):\n",
    "\n",
    "        self.titles1 = titles1\n",
    "        self.titles2 = titles2\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.dic=dic\n",
    "        self.seq_length=seq_length\n",
    "        self.if_test=if_test\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.titles1)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        title1 = self.titles1[idx]\n",
    "        title2 = self.titles2[idx]\n",
    "        \n",
    "        if self.if_test:\n",
    "            # dummy label\n",
    "            label = title1\n",
    "        else:\n",
    "            label = torch.tensor(self.labels[idx])\n",
    "\n",
    "        sample = {'t1': title1, 't2': title2, 'label': label}\n",
    " \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample, self.dic, max_seq_length=self.seq_length)\n",
    " \n",
    "        return sample\n",
    "\n",
    "\n",
    "class Toidx(object):\n",
    "    def __call__(self, sample, word_to_idx, max_seq_length=50):\n",
    "    \n",
    "        def prepare_sequence(seq, to_ix):\n",
    "            #zero padding and word--->ix in seq.\n",
    "            idxs = [to_ix[w] for w in seq.split()]\n",
    "            if len(idxs) > max_seq_length:\n",
    "                idxs = idxs[:max_seq_length] \n",
    "            else:\n",
    "                idxs += [0] * (max_seq_length - len(idxs))\n",
    "            return torch.tensor(idxs, dtype=torch.long)\n",
    "        \n",
    "        t1, t2, label = sample['t1'], sample['t2'], sample[\"label\"]\n",
    "        return {'t1': prepare_sequence(t1, word_to_idx), 't2': prepare_sequence(t2, word_to_idx), 'label': label}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, target_size=3, seq_length=50):\n",
    "        super(LSTM_Classifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size+1, embedding_dim, padding_idx=0)\n",
    "\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, hidden_dim, batch_first=False)\n",
    "        self.lstm2 = nn.LSTM(embedding_dim, hidden_dim, batch_first=False)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.fc1 = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, target_size)\n",
    "        self.initial_hidden = self.init_hidden()\n",
    "        \n",
    "        \n",
    "        self.seq_length=seq_length\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(1, 1, self.hidden_dim),\n",
    "                torch.zeros(1, 1, self.hidden_dim))\n",
    "\n",
    "    def forward(self, sentence1, sentence2):\n",
    "        embeds1 = self.word_embeddings(sentence1)\n",
    "        embeds2 = self.word_embeddings(sentence2)\n",
    "        #print(\"embedding size:\",embeds1.size(), len(sentence1))\n",
    "        \n",
    "        embeds1 = embeds1.view(self.seq_length, len(sentence1), self.embedding_dim)\n",
    "        embeds2 = embeds2.view(self.seq_length, len(sentence1), self.embedding_dim)\n",
    "\n",
    "        lstm_out1, self.hidden = self.lstm1(embeds1)#, self.initial_hidden)\n",
    "        lstm_out2, self.hidden = self.lstm2(embeds2)#, self.initial_hidden)\n",
    "\n",
    "        concat = torch.cat((lstm_out1[-1], lstm_out2[-1]), dim=1)\n",
    "        #print(\"lstm out:\", lstm_out1[-1].size())\n",
    "        #print(\"concat:\", concat.size())\n",
    "        \n",
    "        fc1 = F.relu(self.fc1(concat))\n",
    "        fc2 = F.relu(self.fc2(fc1))\n",
    "        \n",
    "        class_scores = F.log_softmax(fc2)\n",
    "        return class_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:256441, validation data:64111\n",
      "device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanaka/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1,train_loss:0.6205\n",
      "Validation set: Average loss: 0.7169, Accuracy: 43938/64111 (69%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanaka/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type LSTM_Classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2,train_loss:0.6807\n",
      "Validation set: Average loss: 0.7168, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:3,train_loss:0.7096\n",
      "Validation set: Average loss: 0.7168, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:4,train_loss:0.6901\n",
      "Validation set: Average loss: 0.7168, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:5,train_loss:0.7549\n",
      "Validation set: Average loss: 0.7167, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:6,train_loss:0.7696\n",
      "Validation set: Average loss: 0.7168, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:7,train_loss:0.6376\n",
      "Validation set: Average loss: 0.7170, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:8,train_loss:0.6353\n",
      "Validation set: Average loss: 0.7167, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:9,train_loss:0.7533\n",
      "Validation set: Average loss: 0.7167, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:10,train_loss:0.6818\n",
      "Validation set: Average loss: 0.7167, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:11,train_loss:0.6026\n",
      "Validation set: Average loss: 0.7167, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:12,train_loss:0.7536\n",
      "Validation set: Average loss: 0.7168, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:13,train_loss:0.5116\n",
      "Validation set: Average loss: 0.7167, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:14,train_loss:0.7512\n",
      "Validation set: Average loss: 0.7167, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:15,train_loss:0.7219\n",
      "Validation set: Average loss: 0.7167, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:16,train_loss:0.6185\n",
      "Validation set: Average loss: 0.7167, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:17,train_loss:0.7484\n",
      "Validation set: Average loss: 0.7167, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:18,train_loss:0.7953\n",
      "Validation set: Average loss: 0.7167, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:19,train_loss:0.6776\n",
      "Validation set: Average loss: 0.7167, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:20,train_loss:0.6944\n",
      "Validation set: Average loss: 0.7166, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:21,train_loss:0.7522\n",
      "Validation set: Average loss: 0.7167, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:22,train_loss:0.6748\n",
      "Validation set: Average loss: 0.7167, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:23,train_loss:0.6793\n",
      "Validation set: Average loss: 0.7167, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:24,train_loss:0.7784\n",
      "Validation set: Average loss: 0.7167, Accuracy: 43938/64111 (69%)\n",
      "\n",
      "epoch:25,train_loss:0.7229\n",
      "Validation set: Average loss: 0.7168, Accuracy: 43938/64111 (69%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 256\n",
    "HIDDEN_DIM = 128\n",
    "max_seq_length = 50\n",
    "\n",
    "title1_en = list(train_df[\"title1_en\"])\n",
    "title2_en = list(train_df[\"title2_en\"])\n",
    "\n",
    "\n",
    "\n",
    "train1_en, val1_en, train2_en, val2_en, y_train, y_val = train_test_split(title1_en, title2_en, y, test_size=0.2, random_state=42)\n",
    "print(\"training data:{}, validation data:{}\".format(len(y_train), len(y_val)))\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\",device)\n",
    "\n",
    "model = LSTM_Classifier(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), target_size=3, seq_length=max_seq_length)\n",
    "model.to(device)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "#loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "train_dataset = TitleDataset(train1_en, train2_en, y_train, dic=word_to_ix, transform=Toidx(), seq_length=max_seq_length)\n",
    "val_dataset = TitleDataset(val1_en, val2_en, y_val, dic=word_to_ix, transform=Toidx(), seq_length=max_seq_length)\n",
    "\n",
    "\n",
    "batch=64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, sample_batch in enumerate(train_loader):\n",
    "        #print(\"batch_idx:\",batch_idx)\n",
    "        en_title1 = sample_batch[\"t1\"].to(device)\n",
    "        en_title2 = sample_batch[\"t2\"].to(device)\n",
    "        y = sample_batch[\"label\"].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(en_title1, en_title2)\n",
    "        \n",
    "        loss = loss_function(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"epoch:{},train_loss:{:.4f}\".format(epoch+1 ,loss))\n",
    "            \n",
    "    return model\n",
    "    \n",
    "        \n",
    "\n",
    "def test():\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for batch_idx, sample_batch in enumerate(val_loader):\n",
    "            en_title1 = sample_batch[\"t1\"].to(device)\n",
    "            en_title2 = sample_batch[\"t2\"].to(device)\n",
    "            y = sample_batch[\"label\"].to(device)\n",
    "            \n",
    "            output = model(en_title1, en_title2)\n",
    "\n",
    "            # sum up batch loss\n",
    "            test_loss += loss_function(output, y).item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            #print(pred.eq(y.view_as(pred)).sum().item())\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "\n",
    "        #test_loss /= len(val_loader.dataset)\n",
    "        test_loss /= batch_idx\n",
    "        print('Validation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "              .format(test_loss, correct, len(val_loader.dataset),\n",
    "                      100. * correct / len(val_loader.dataset)))    \n",
    "        return test_loss\n",
    "\n",
    "        \n",
    "def save_model(model, path=\"model/LSTM.model\"):\n",
    "    torch.save(model, path)  \n",
    "        \n",
    "lowest_loss = 1000000000\n",
    "for epoch in range(100):\n",
    "    #print(epoch+1)\n",
    "    model = train(epoch)\n",
    "    val_loss = test()\n",
    "    \n",
    "    if val_loss < lowest_loss:\n",
    "        #print(\"saving model...\")\n",
    "        lowest_loss = val_loss\n",
    "        save_model(model)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 18482, 0: 43938, 2: 1691})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter(y_val)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de16793b539f4196aee2f0b7f5ee00d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=626), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanaka/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/home/tanaka/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/home/tanaka/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "#推論\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "EMBEDDING_DIM = 256\n",
    "HIDDEN_DIM = 128\n",
    "max_seq_length = 50\n",
    "\n",
    "model = LSTM_Classifier(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), target_size=3, seq_length=max_seq_length)\n",
    "\n",
    "PATH = \"model/LSTM.model\"\n",
    "model = torch.load(PATH)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "title1_en_test = list(test_df[\"title1_en\"])\n",
    "title2_en_test = list(test_df[\"title2_en\"])\n",
    "id_ = test_df[\"id\"]\n",
    "\n",
    "# test dataset. label is None.\n",
    "test_dataset = TitleDataset(title1_en_test, title2_en_test , None, dic=word_to_ix, transform=Toidx(), seq_length=max_seq_length, if_test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    for sample_batch in tqdm(test_loader):\n",
    "        en_title1 = sample_batch[\"t1\"].to(device)\n",
    "        en_title2 = sample_batch[\"t2\"].to(device)\n",
    "        output = model(en_title1, en_title2)\n",
    "        \n",
    "        pred = output.max(1, keepdim=True)[1].cpu()\n",
    "        #print(output.cpu(), pred)\n",
    "        predictions.extend(list(pred.numpy()))\n",
    "        \n",
    "#'unrelated', 0\n",
    "#'agreed', 1\n",
    "#'disagreed', 2\n",
    "\n",
    "new_predictions = []\n",
    "for p in predictions:\n",
    "    if p == 0:\n",
    "        new_predictions.append(\"unrelated\")\n",
    "    elif p==1:\n",
    "        new_predictions.append(\"agreed\")\n",
    "    elif p==2:\n",
    "        new_predictions.append(\"disagreed\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'unrelated': 80126})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter(new_predictions)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>321187</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321190</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321189</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321193</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321191</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>321194</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>321192</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>321197</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>321195</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>321199</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>321198</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>321201</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>321196</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>321200</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>321203</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>321202</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>321206</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>321204</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>321207</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>321208</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>321205</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>321209</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>321211</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>321210</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>321214</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>321213</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>321215</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>321212</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>321218</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>321220</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80096</th>\n",
       "      <td>401533</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80097</th>\n",
       "      <td>401536</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80098</th>\n",
       "      <td>401538</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80099</th>\n",
       "      <td>401539</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80100</th>\n",
       "      <td>401537</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80101</th>\n",
       "      <td>401540</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80102</th>\n",
       "      <td>401541</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80103</th>\n",
       "      <td>401544</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80104</th>\n",
       "      <td>401543</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80105</th>\n",
       "      <td>401546</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80106</th>\n",
       "      <td>401542</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80107</th>\n",
       "      <td>401545</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80108</th>\n",
       "      <td>401547</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80109</th>\n",
       "      <td>401549</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80110</th>\n",
       "      <td>401551</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80111</th>\n",
       "      <td>401548</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80112</th>\n",
       "      <td>401552</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80113</th>\n",
       "      <td>401553</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80114</th>\n",
       "      <td>401554</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80115</th>\n",
       "      <td>401550</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80116</th>\n",
       "      <td>401556</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80117</th>\n",
       "      <td>401557</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80118</th>\n",
       "      <td>401558</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80119</th>\n",
       "      <td>401555</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80120</th>\n",
       "      <td>401561</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80121</th>\n",
       "      <td>401559</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80122</th>\n",
       "      <td>401560</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80123</th>\n",
       "      <td>401562</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80124</th>\n",
       "      <td>401563</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80125</th>\n",
       "      <td>401564</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80126 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id   Category\n",
       "0      321187  unrelated\n",
       "1      321190  unrelated\n",
       "2      321189  unrelated\n",
       "3      321193  unrelated\n",
       "4      321191  unrelated\n",
       "5      321194  unrelated\n",
       "6      321192  unrelated\n",
       "7      321197  unrelated\n",
       "8      321195  unrelated\n",
       "9      321199  unrelated\n",
       "10     321198  unrelated\n",
       "11     321201  unrelated\n",
       "12     321196  unrelated\n",
       "13     321200  unrelated\n",
       "14     321203  unrelated\n",
       "15     321202  unrelated\n",
       "16     321206  unrelated\n",
       "17     321204  unrelated\n",
       "18     321207  unrelated\n",
       "19     321208  unrelated\n",
       "20     321205  unrelated\n",
       "21     321209  unrelated\n",
       "22     321211  unrelated\n",
       "23     321210  unrelated\n",
       "24     321214  unrelated\n",
       "25     321213  unrelated\n",
       "26     321215  unrelated\n",
       "27     321212  unrelated\n",
       "28     321218  unrelated\n",
       "29     321220  unrelated\n",
       "...       ...        ...\n",
       "80096  401533  unrelated\n",
       "80097  401536  unrelated\n",
       "80098  401538  unrelated\n",
       "80099  401539  unrelated\n",
       "80100  401537  unrelated\n",
       "80101  401540  unrelated\n",
       "80102  401541  unrelated\n",
       "80103  401544  unrelated\n",
       "80104  401543  unrelated\n",
       "80105  401546  unrelated\n",
       "80106  401542  unrelated\n",
       "80107  401545  unrelated\n",
       "80108  401547  unrelated\n",
       "80109  401549  unrelated\n",
       "80110  401551  unrelated\n",
       "80111  401548  unrelated\n",
       "80112  401552  unrelated\n",
       "80113  401553  unrelated\n",
       "80114  401554  unrelated\n",
       "80115  401550  unrelated\n",
       "80116  401556  unrelated\n",
       "80117  401557  unrelated\n",
       "80118  401558  unrelated\n",
       "80119  401555  unrelated\n",
       "80120  401561  unrelated\n",
       "80121  401559  unrelated\n",
       "80122  401560  unrelated\n",
       "80123  401562  unrelated\n",
       "80124  401563  unrelated\n",
       "80125  401564  unrelated\n",
       "\n",
       "[80126 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_csv = pd.concat([id_, pd.Series(new_predictions)], axis=1)\n",
    "#display(submit_csv)\n",
    "\n",
    "submit_csv.columns = [\"Id\", \"Category\"]\n",
    "submit_csv.to_csv(\"submit.csv\", header=True, index=False)\n",
    "submit = pd.read_csv(\"submit.csv\")\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>347448</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>347449</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>359100</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>359101</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>359102</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>359103</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>359104</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>359105</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>359106</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>359107</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>359108</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>359109</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>353889</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>353888</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>353883</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>353882</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>353881</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>353880</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>353887</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>353886</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>353885</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>353884</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>322906</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>322907</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>322904</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>322905</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>322902</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>322903</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>322900</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>322901</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80096</th>\n",
       "      <td>393395</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80097</th>\n",
       "      <td>384932</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80098</th>\n",
       "      <td>393399</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80099</th>\n",
       "      <td>393398</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80100</th>\n",
       "      <td>399940</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80101</th>\n",
       "      <td>399941</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80102</th>\n",
       "      <td>399942</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80103</th>\n",
       "      <td>399943</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80104</th>\n",
       "      <td>399944</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80105</th>\n",
       "      <td>399945</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80106</th>\n",
       "      <td>399946</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80107</th>\n",
       "      <td>399947</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80108</th>\n",
       "      <td>399948</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80109</th>\n",
       "      <td>399949</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80110</th>\n",
       "      <td>379414</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80111</th>\n",
       "      <td>379415</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80112</th>\n",
       "      <td>379416</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80113</th>\n",
       "      <td>398010</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80114</th>\n",
       "      <td>379417</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80115</th>\n",
       "      <td>398019</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80116</th>\n",
       "      <td>398018</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80117</th>\n",
       "      <td>367742</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80118</th>\n",
       "      <td>398015</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80119</th>\n",
       "      <td>379410</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80120</th>\n",
       "      <td>398017</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80121</th>\n",
       "      <td>398016</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80122</th>\n",
       "      <td>398011</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80123</th>\n",
       "      <td>384939</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80124</th>\n",
       "      <td>398013</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80125</th>\n",
       "      <td>379411</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80126 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id   Category\n",
       "0      347448  unrelated\n",
       "1      347449  unrelated\n",
       "2      359100  unrelated\n",
       "3      359101  unrelated\n",
       "4      359102  unrelated\n",
       "5      359103  unrelated\n",
       "6      359104  unrelated\n",
       "7      359105  unrelated\n",
       "8      359106  unrelated\n",
       "9      359107  unrelated\n",
       "10     359108  unrelated\n",
       "11     359109  unrelated\n",
       "12     353889  unrelated\n",
       "13     353888  unrelated\n",
       "14     353883  unrelated\n",
       "15     353882  unrelated\n",
       "16     353881  unrelated\n",
       "17     353880  unrelated\n",
       "18     353887  unrelated\n",
       "19     353886  unrelated\n",
       "20     353885  unrelated\n",
       "21     353884  unrelated\n",
       "22     322906  unrelated\n",
       "23     322907  unrelated\n",
       "24     322904  unrelated\n",
       "25     322905  unrelated\n",
       "26     322902  unrelated\n",
       "27     322903  unrelated\n",
       "28     322900  unrelated\n",
       "29     322901  unrelated\n",
       "...       ...        ...\n",
       "80096  393395  unrelated\n",
       "80097  384932  unrelated\n",
       "80098  393399  unrelated\n",
       "80099  393398  unrelated\n",
       "80100  399940  unrelated\n",
       "80101  399941  unrelated\n",
       "80102  399942  unrelated\n",
       "80103  399943  unrelated\n",
       "80104  399944  unrelated\n",
       "80105  399945  unrelated\n",
       "80106  399946  unrelated\n",
       "80107  399947  unrelated\n",
       "80108  399948  unrelated\n",
       "80109  399949  unrelated\n",
       "80110  379414  unrelated\n",
       "80111  379415  unrelated\n",
       "80112  379416  unrelated\n",
       "80113  398010  unrelated\n",
       "80114  379417  unrelated\n",
       "80115  398019  unrelated\n",
       "80116  398018  unrelated\n",
       "80117  367742  unrelated\n",
       "80118  398015  unrelated\n",
       "80119  379410  unrelated\n",
       "80120  398017  unrelated\n",
       "80121  398016  unrelated\n",
       "80122  398011  unrelated\n",
       "80123  384939  unrelated\n",
       "80124  398013  unrelated\n",
       "80125  379411  unrelated\n",
       "\n",
       "[80126 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
